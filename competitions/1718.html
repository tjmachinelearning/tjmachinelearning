<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="UTF-8">
    <title>Competitions | TJ Machine Learning Club</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" type="text/css" href="../stylesheets/normalize.css" media="screen">
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="../stylesheets/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css" href="../stylesheets/github-light.css" media="screen">
    <link rel="stylesheet" type="text/css" href="../css/demo.css" />
    <link rel="stylesheet" type="text/css" href="../css/component.css" />
    <link rel="stylesheet" type="text/css" href="../css/style1.css" />
    <script src="../js/modernizr.custom.js"></script>
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.1.0/jquery.min.js"></script>
    <script src="../js/expand.js"></script>

    <link rel="apple-touch-icon" sizes="180x180" href="../apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
    <link rel="manifest" href=../"manifest.json">
    <link rel="mask-icon" href="../safari-pinned-tab.svg" color="#5bbad5">
    <meta name="theme-color" content="#ffffff">

	<script>
	  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

	  ga('create', 'UA-105333430-1', 'auto');
	  ga('send', 'pageview');

	</script>

  </head>
  <body>
    <div class="content">
    <div class="mobile-menu">
      <button id="trigger-overlay" type="button" style="background:none; border:none; position: fixed;">
        <img src="../img/menu.png" alt="Menu" style="max-width:2em">
      </button>
    </div>
    <section class="page-header">
        <h1 class="project-name" style="color:#fff">TJ Machine Learning Club</h1>
        <h2 class="project-tagline" style="color:#fff">Making AI more accessible</h2>
        <a href="https://docs.google.com/forms/d/e/1FAIpQLSe10g6jeb8k39RG4RZCrRRyWnltXBFEN6--q4t2xgAo6ddJQA/viewform?usp=sf_link" class="btn" style="color:#fff">Join Us Today</a>
    </section>
    <div class="container">
         <section class="section section--menu" id="Alonso">
             <span class="link-copy"></span>
             <nav class="menu menu--alonso">
                 <ul class="menu__list">
                     <li class="menu__item"><a href="../" class="menu__link">Home</a></li>
                     <li class="menu__item"><a href="../schedule/1920" class="menu__link">Lectures</a></li>
                     <li class="menu__item"><a href="../rankings" class="menu__link">Rankings</a></li>
                     <li class="menu__item"><a href="../resources" class="menu__link">Resources</a></li>
                     <li class="menu__item"><a href="../research" class="menu__link">Research</a></li>
                     <li class="menu__item menu__item--current"><a href="#" class="menu__link">Competitions</a></li>
                     <li class="menu__line"></li>
                 </ul>
             </nav>
         </section>
    </div>

        <div class="overlay overlay-hugeinc">
    			<button type="button" class="overlay-close">Close</button>
    			<nav>
    				<ul>
    					<li><a href="../">Home</a></li>
    					<li><a href="../schedule/1819">Lectures</a></li>
    					<li><a href="../rankings">Rankings</a></li>
    					<li><a href="../resources">Resources</a></li>
    					<li><a href="../research">Research</a></li>
                        <li><a href="#">Competitions</a></li>
    				</ul>
    			</nav>
    		</div>

    <section class="main-content">

        <h3>Competition Instructions</h3>

        <div class="mobileyear">
            <section class="section section--menu" id="yearnav">
                <span class="link-copy"></span>
                <nav class="menu menu--yearnav">
                    <ul class="menu__list">
                        <li class="menu__item"><a class="menu__link" href="1920">19&ndash;20</a></li>
                        <li class="menu__item"><a class="menu__link" href="1819">18&ndash;19</a></li>
                        <li class="menu__item  menu__item--current"><a class="menu__link" href="#">17&ndash;18</a></li>
                        <li class="menu__item"><a class="menu__link" href="1617">16&ndash;17</a></li>
                        <li class="menu__line"></li>
                    </ul>
                </nav>
            </section>
        </div>
        <div class="desktopyear">
            <section class="section section--menu" id="yearnav">
                <span class="link-copy"></span>
                <nav class="menu menu--yearnav">
                    <ul class="menu__list">
                        <li class="menu__item"><a class="menu__link" href="1920">2019&ndash;2020</a></li>
                        <li class="menu__item"><a class="menu__link" href="1819">2018&ndash;2019</a></li>
                        <li class="menu__item  menu__item--current"><a class="menu__link" href="#">2017&ndash;2018</a></li>
                        <li class="menu__item"><a class="menu__link" href="1617">2016&ndash;2017</a></li>
                        <li class="menu__line"></li>
                    </ul>
                </nav>
            </section>
        </div>

            <!--Begin Competition Content-->
            <div class="instructions">
                <div class="box">
                    <div class="instructheader"><h4 id="kaggletitle">Iceberg Competition Instructions</h4></div>
                    <section id="kaggle" style="display:none; padding: 0rem 0rem 1rem 0rem">
                        <hr>
                        <h4>Competition Introduction</h4>
                            <p>For the next few weeks, in lieu of our own internal competitions, you have the opportunity to participate in a public <a href="https://kaggle.com">Kaggle</a> competition. Your performance on this competition will be counted in our club rankings.</p>
                            <p>The competition we have chosen is the <a href="https://www.kaggle.com/c/statoil-iceberg-classifier-challenge">Statoil/C-CORE Iceberg Classifier Challenge</a>. Essentially, the goal is to classify ships vs. icebergs given images. Just like any of our previous competitions, you aim to achieve the highest accuracy and be at the top of the leaderboard.
                            The procedure for participating is also similar to our in-class competitions. Download the training and testing data, train on the training data, generate a submission file from the testing data, and upload the submission file for grading. The private leaderboard results determine final rankings, and are made available after the final deadline.</p>
                            <p>Since this competition is difficult and long, you are allowed to work individually or in teams of 2.</p>

                	    <h4>Differences between Public and Private Kaggle Competitions</h4>
                            <p>However, there are a few differences between a public Kaggle competitions and our private classroom competitions:</p>

                        <ul>
                            <li>Anyone can enter a public Kaggle competition (obviously). There are currently 2,000+ teams in the Iceberg competition.</li>
    		                <li>There are monetary prizes! They range from $10,000 to >$1,000,000. The iceberg competition in particular has prizes of $25,000 for 1st, $15,000 for 2nd, and $10,000 for 3rd.</li>
                        </ul>

                        <p>One might ask: Why are such large sums of money being given out for classifying ships vs. icebergs? Well, this competition is sponsored by a shipping company. So, telling an iceberg vs. another ship more accurately could prevent a collision and save them millions of dollars. However, they clearly don't want to hire a data scientists, so they essentially crowdsourcing their solution through Kaggle. They take the winner's model and use it for their business.</p>
                        <p>Some more differences between a public Kaggle competition and our in-class competitions:</p>

                        <ul>
                            <li>Data size tends to be much larger (sometimes on the order of 1 TB). We partially chose this competition due to the low data size (~1 GB).</li>
                            <li>Even with this relatively low data size for a public competition, you will need a complex model. If the answer was trivial and could be achieved simply, they wouldn't be offering $50,000.</li>
                            <li>Because you will need a complex model, you will need a GPU to run your models. You can begin writing your code now, and we will try to get more machines with GPUs running in the syslab soon. The machine "infosphere" currently has the only high-performance GPUs in the syslab.</li>
                            <li>Rather than viewing our website for information about the data and competition procedures, everything is directly on the competition site itself. The competition link is below.</li>
                            <li>Public competitions last months, not one week. This competition ends on January 23rd, 2017. Do not delay. Begin as soon as possible. Everything takes far longer than expected to complete, especially when working with large amounts of data.</li>
                            <li>People discuss solutions and post code in the <a href="https://www.kaggle.com/c/statoil-iceberg-classifier-challenge/discussion">Discussion tab</a>. Of course, the leaders of competition aren't going to give to the world their winning solution while the competition is ongoing, but you can often find a half-decent model available. I recommend viewing and understanding what people have done and made available.</li>
                        </ul>

                        <h4>Tips</h4>
                            <p>Consider all the techniques we have recently covered: Convolutional networks, transfer learning, Inception and ResNet, image preprocessing, image normalization, data augmentation, etc. Some may be useful, others will not.</p>
                            <p>If you chose to use PyTorch, which is faster and lower-level but has less documentation, <a href="http://pytorch.org/tutorials/beginner/transfer_learning_tutorial">this tutorial</a> on transfer learning may be helpful when starting out. If you use Keras, <a href="https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data">this tutorial</a> may be useful for beginners. If you're stuck, and can't figure out how to do something, Google it or check the documentation.</p>

                        <h4>Final words</h4>
                            <p>I will leave you with these final words: Public competitions are very hard. Don't be discouraged if you don't do well initially. Training, retraining, and tweaking your models are essential for your success. If you do well, say, in the top 5%, it is extremely impressive. I'm not aware of a high school student who has won any significant money from Kaggle competitionsâ€“think about it. Just as you will be working on this in your free time, so are PhD's, graduate students, and data scientists.</p>
                            <p>Good Luck!</p>
                            <a href="https://www.kaggle.com/c/statoil-iceberg-classifier-challenge">Competition Link</a>
                    </section>
                </div>
                <div class="box">
                    <div class="instructheader"><h4 id=cnntitle>Convolutional Neural Networks Competition Instructions</h4></div>
                    <section id="cnn" style="display:none">
                        <hr>
                        <p>Each predicted keypoint is specified by an (x,y) real-valued pair in the space of pixel indices. There are 15 keypoints, which represent the following elements of the face:</p>
                        <p>left_eye_center, right_eye_center, left_eye_inner_corner, left_eye_outer_corner, right_eye_inner_corner, right_eye_outer_corner, left_eyebrow_inner_end, left_eyebrow_outer_end, right_eyebrow_inner_end, right_eyebrow_outer_end, nose_tip, mouth_left_corner, mouth_right_corner, mouth_center_top_lip, mouth_center_bottom_lip</p>
                        <p>Left and right here refers to the point of view of the subject.</p>
                        <p>The input image is given in the last field of the data files, and consists of a list of pixels (ordered by row), as integers in (0,255). The images are 96x96 pixels.</p>
                        <h4>Data files</h4>
                        <ul>
                            <li><strong>train.csv</strong>: list of training 5000 images. Each row contains the (x,y) coordinates for 15 keypoints, and image data as row-ordered list of pixels. The first row is the header and associates each column with the feature. There are 31 values in each row, with the first 30 being x value for feature 1, y value for feature 1, etc and the 31st value being the image. The first 30 should be the outputs of your network and the 31st (image) should be the input.</li>
                            <li><strong>test.csv</strong>: list of 2049 test images. Each row contains ImageId and image data as row-ordered list of pixels.</li>
                            <li><strong>samplesubmission.csv</strong>: list of keypoints to predict. Each row has an Id and a value. The Id corresponds to the image and feature in the format "ImageId.FeatureId" where featureId is based on the order in which they are sorted in the train file. For example, the first feature is left_eye_center_x so to predict left_eye_center_x for image 1, I would have "1.1 34.555" as the first row.</li>
                        </ul>
                        <h4>Helpful tips</h4>
                        <ul>
                    	    <li><a href="../contests/1718/cnn/IO_sample.py.txt">Sample code</a></li>
                    	    <li>Use Keras. Documentation available <a href="https://keras.io">here</a>. The first half of <a href="https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data">this tutorial</a> may come in handy. Our introductory lecture is available <a href="https://tjmachinelearning.com/lectures/1718/library/keras">here</a>.</li>
                            <li>Start with a stadard neural network before moving on to a convolutional one. When you do use a convolutional network,
                             make sure to reshape your input to 96x96 instead of 1x9216 as it is right now. This is best done using numpy.</li>
                            <li>Use a linear activation in the final layer because the challenge is regression not classification. There should be 30 output nodes.</li>
                            <li>The Ids start at 1 not 0. Don't mix this up.</li>
                            <li>Don't forget your header in the submission file.</li>
                        </ul>
                        <p>To better understand the format, open the files in Excel. Feel free to ask any clarifying format questions to the officers.</p>
                        <p><a href="https://www.kaggle.com/c/tjmlfacialfeatures">Competition link</a></p>
                    </section>
                </div>
                <div class="box">
                   <div class="instructheader"><h4 id=nntitle>Neural Networks Competition Instructions</h4></div>
                   <section id="nn" style="display:none">
                       <hr>
    		            <p><i>11/01/17 -&emsp;</i>Your job is to write the code to create an neural network, train it on the training data, and use it to predict the classes of the testing data. We are trying to images of handwritten digits. The data we are using is from the famous MNIST dataset. Your neural network is supposed to classify which digit (0,1,2,3,4,5,6,7,8, or 9) the image represents, and the inputs are the 784 values that make up the 28x28 images.</p>
                        <p>The training data looks like this:</p>
                		<code>label, pixel 11, pixel 12, pixel 13, pixel 14, etc. (784 pixel values)<br>
                		label, pixel 21, pixel 22, pixel 23, pixel 24, etc. (784 pixel values)<br>
                		label, pixel 31, pixel 32, pixel 33, pixel 34, etc. (784 pixel values)<br>
                		etc. (60,000 lines)</code>

                		<p>The testing data looks like this:</p>
                		<p></p><code>id, pixel 11, pixel 12, pixel 13, pixel 14, etc. (784 pixel values)<br>
                		id, pixel 21, pixel 22, pixel 23, pixel 24, etc. (784 pixel values)<br>
                		id, pixel 31, pixel 32, pixel 33, pixel 34, etc. (784 pixel values)<br>
                		etc. (10,000 lines)</code></p>

        		        <p>Where <code>pixel ij</code> is the pixel value in the <code>ith</code> row and <code>jth</code> column. Each image is 28x28. Each pixel value ranges from 0, black, to 255, white. The MNIST dataset is black and white, which is why each pixel value is a single value instead of an (R,G,B) triple.</p>

                		<p>Your end goal is to create a file which looks like:</p>
                		<p><code>id, solution <br>
                		1, predicted_label<br>
                		2, predicted_label<br>
                		3, predicted_label<br>
                		4, predicted_label<br>
                		etc. (10,000 lines)</code></p>

        		        <p>All <a href="#standard">standard competition rules</a> apply. You are only allowed to use the numpy library. We highly recommend you use the library for vectors (bias vectors, etc.) and matrices (weights, partial matrices).</p>
                        <p>We've written a <a href="../lectures/1718/nn3/nn_shell.py.txt">small shell</a>. The shell has a network class, and each network is made up of a list of layers (which are a separate class). Each layer is designed to have its own vectors and matrices (biases and weights, etc.). You don't have to structure your network this way by any means, or have a layer class at all. Most of the time when people write neural networks from scratch, they only have a single network class.</p>
                        <p>The competition ends in two weeks, at 11:59:59 p.m. on 11/14/17, since our next meeting is 11/15. Also, since writing a neural network from scratch is an involved process, the competition will be worth double in our rankings.</p>
                        <p><a href="https://www.kaggle.com/c/nncontest3">Competition link</a></p>
    	            </section>
                </div>
                <div class="box">
        	           <div class="instructheader"><h4 id=svmtitle>Support Vector Machine Competition Instructions</h4></div>
                       <section id="svm" style="display:none">
                       <hr>
            	       <p><i>10/04/17 -&emsp;</i>Your job is to write the code to create an SVM, train it on the training data, and use it to predict the classes of the testing data.
                    	We are trying to classify survival of passengers on the Titanic. The data we are using are from actual passengers on the ship.
                    	Your SVM is supposed to classify whether a passenger survived [RIP (0) or Survived (1)], based on 11 different metrics (features).</p>
            	       <p>The purpose of this contest is not to test your ability to write an SVM. Instead, we are using this opportunity to test two abilities:</p>
                	  <ol>
                		  <li>Your ability to learn how to use Scikit-Learn</li>
                		  <li>Your ability to work with real-world data</li>
                	  </ol>
                	  <p>
                		  The second is far more important (and difficult) than the first. With that in mind, the training data now looks like this:
                	  </p>
                	  	<p>
                		 <code>
                			feature 1, survival, feature 2, feature 3, feature 4, feature 5, feature 6, feature 7, feature 8, feature 9, feature 10, feature 11<br>
                			feature 1, survival, feature 2, feature 3, feature 4, feature 5, feature 6, feature 7, feature 8, feature 9, feature 10, feature 11<br>
                			feature 1, survival, feature 2, feature 3, feature 4, feature 5, feature 6, feature 7, feature 8, feature 9, feature 10, feature 11<br>
                			etc. (636 lines) <br></code>
                		</p>
                		<p>and the testing data looks like this: </p>
                		<p>
                		<code>
                			feature 1, feature 2, feature 3, feature 4, feature 5, feature 6, feature 7, feature 8, feature 9, feature 10, feature 11<br>
                			feature 1, feature 2, feature 3, feature 4, feature 5, feature 6, feature 7, feature 8, feature 9, feature 10, feature 11<br>
                			feature 1, feature 2, feature 3, feature 4, feature 5, feature 6, feature 7, feature 8, feature 9, feature 10, feature 11<br>
                			etc. (255 lines) <br>
                		</code>
                        	</p>
            		   <p>Your end goal is to create a file which looks like: <br>
            			<code>
            			id, solution <br>
            			1, predicted_class <br>
            			2, predicted_class <br>
            			3, predicted_class <br>
            			4, predicted_class <br>
            			etc. (255 lines) <br>
            			</code>
                   		For every set of features in line N in the training data, you should have a line <code>N, predicted_class</code> in your submission file.</p>
            	        <p><strong>There are missing data points. Some features are not useful. The difficult part of this contest is formatting the data given, determining which features are useful, which ones should be trained on, and how to deal with the missing data.</strong></p>
                        <p>Your are allowed to (and should) use <a href="http://www.scikit-learn.org">Scikit-Learn</a> to create your SVM. Scikit has detailed instructions on how to write an SVM using the library <a href="http://scikit-learn.org/stable/modules/svm">here</a>. This is the trivial portion of the competition.</p>
                	    <p>We highly recommend you open both the training and testing csv files in a program like Excel, which will help you modify columns of data and perform calculations quickly.</p>
                	    <p><a href="../contests/1718/rf/IO_sample.py.txt">The Data I/O code</a> from the decision tree lecture may still be useful.</p>
                	    <p><a href="https://www.kaggle.com/t/84362979276c4a219871ba63161aadcc">Competition Link</a></p>
                	    <p><a href="#standard">Standard competition rules</a> apply, except for Rule #1, since we are using Scikit-Learn.</p>
                    </section>
                </div>
                <div class="box">
                    <div class="instructheader"><h4 id=rftitle>Random Forests Competition Instructions</h4></div>
                    <section id="rf" style="display:none">
                        <hr>
                        <p><i>9/27/17 -&emsp;</i>Your job is to write the code to create a random forest, train it on the training data, and use it to predict the classes of the testing data.
                        We are trying to classify survival of passengers on the Titanic. The data we are using are from actual passengers on the ship.
                        Your random forest is supposed to classify whether a passenger survived [RIP (0) or Survived (1)], based on 7 different metrics (features).
                        The training data looks like this: </p>
                        <p>
                        <code>
                        feature 1, feature 2, feature 3, feature 4, feature 5, feature 6, feature 7, survival<br>
                        feature 1, feature 2, feature 3, feature 4, feature 5, feature 6, feature 7, survival<br>
                        feature 1, feature 2, feature 3, feature 4, feature 5, feature 6, feature 7, survival<br>
                        etc. (500 lines) <br></code>
                        </p>
                        <p>
                        and the testing data looks like this: </p>
                        <p>
                        <code>
                        feature 1, feature 2, feature 3, feature 4, feature 5, feature 6, feature 7<br>
                        feature 1, feature 2, feature 3, feature 4, feature 5, feature 6, feature 7<br>
                        feature 1, feature 2, feature 3, feature 4, feature 5, feature 6, feature 7<br>
                        etc. (214 lines) <br>
                        </code>
                        </p>
                        <p>
                        Your end goal is to create a file which looks like: <br>
                        <code>
                        id, solution <br>
                        1, predicted_class <br>
                        2, predicted_class <br>
                        3, predicted_class <br>
                        4, predicted_class <br>
                        etc. (214 lines) <br>
                        </code>

                        For every set of features in line N in the training data, you should have a line <code>N, predicted_class</code> in your submission file.
                        </p>
                    	<p><a href="#standard">Standard competition instructions and rules</a> apply.</p>
                    	<p><a href="https://www.kaggle.com/t/458d4811158b4d15a0c4e337189608ac">Competition Link</a>
                        <p> In case you care, the features correspond to: </p>
                        <code>
                            pclass - Ticket class: 1 = 1st, 2 = 2nd, 3 = 3rd </br>
                            sex	- Sex: 0 = Male, 1 = Female <br>
                            Age - Age in years	<br>
                            sibsp - # of siblings / spouses aboard the Titanic	<br>
                            parch - # of parents / children aboard the Titanic	<br>
                            fare - passenger fare <br>
                            embarked - Port of Embarkation: 0 = Southampton, 1 = Cherbourg, 2 = Queenstown<br>
                            survival - Survival: 0 = No, 1 = Yes<br>
                        </code>
                        </p>
                    	<p>Shell code is available <a href="../contests/1718/rf/shell.py.txt">here</a>.
                    	<a href="../contests/1718/dct/IO_sample.py.txt">The Data I/O code</a> from the decision tree lecture will still be useful, but will need to be adapted for this data.
                            </p>
                    </section>
                </div>
                <div class="box">
                    <div class="instructheader"><h4 id=firsttitle>2017-2018 First Competition Instructions</h4></div>
                    <section id="first" style="display:none">
                        <hr>
                        <h4>The Data</h4>
                        <p><i>9/20/17 -&emsp;</i>Welcome to the first contest of the year! Your job is to write the code to create a decision tree, train it on the training data, and use it to predict the classes of the testing data.
                        We are trying to classify breast cancer data. The data we are using is actual data from breast cancer patients.
                        Your decision tree is supposed to classify the type of breast cancer they have (benign (0) or malignant (1)), based on 9 different metrics (features).
                        The training data looks like this: </p>
                        <p>
                        <code>
                        feature 1, feature 2, feature 3, feature 4, feature 5, feature 6, feature 7, feature 8, feature 9, class <br>
                        feature 1, feature 2, feature 3, feature 4, feature 5, feature 6, feature 7, feature 8, feature 9, class <br>
                        feature 1, feature 2, feature 3, feature 4, feature 5, feature 6, feature 7, feature 8, feature 9, class <br>
                        etc. (533 lines) <br></code>
                        </p>
                        <p>
                        and the testing data looks like this: </p>
                        <p>
                        <code>
                        feature 1, feature 2, feature 3, feature 4, feature 5, feature 6, feature 7, feature 8, feature 9 <br>
                        feature 1, feature 2, feature 3, feature 4, feature 5, feature 6, feature 7, feature 8, feature 9 <br>
                        feature 1, feature 2, feature 3, feature 4, feature 5, feature 6, feature 7, feature 8, feature 9 <br>
                        etc. (150 lines) <br>
                        </code>
                        </p>
                        <p>
                        Your end goal is to create a file which looks like: <br>
                        <code>
                        id, solution <br>
                        1, predicted_class <br>
                        2, predicted_class <br>
                        3, predicted_class <br>
                        4, predicted_class <br>
                        etc. (150 lines) <br>
                        </code>

                        For every set of features in line N in the training data, you should have a line <code>N, predicted_class</code> in your submission file. </p>
                        <p>Shell code is available on the <a href="../schedule/1718">lecture schedule page</a>.
                            The Data I/O code from the decision tree lecture will still be useful, but will need to be adapted for this data.
                        </p>
                        <h4>How to participate</h4>
                        <p>
                        	Our contests will be held on <a href="https://kaggle.com">Kaggle</a>, using <a href="https://inclass.kaggle.com">Kaggle InClass</a>. This allows us to upload data and competition instructions, as well as impose submission deadlines. It also ranks submissions automatically!

                        	To participate:</p>
                        <p>
                        <ol><li>Create a Kaggle account by clicking "sign up" in the top right.
                        </li><li>Click on <a href="https://www.kaggle.com/t/cb7c483774b8408582fd138a3a49b0d4">this link</a> (the competition link).
                        </li><li>Download the training and testing data.
                        </li><li>Download the I/O Code.
                        </li><li>Write your algorithm and train it on the training data.
                        </li><li>Then, test it on the testing data, creating a submission file with the predicted ground truth in the format shown in the sample submission file.
                        </li><li>Upload your submission file and see your results!
                        </li><li>Tweak your code, repeating steps 5-8 to improve your accuracy and move up the leaderboard.
                        </ol>
                        </p>
                        <p>
                        Some More Rules:
                        <ol>
                        <li>Use Python. Everything we do is in Python this year. Don't use a library, other than numpy. For this contest only, if you have no Python experience, you can use whatever language you are comfortable with.
                        </li><li>The Competition ends at 11:59:00 PM next Monday, 9/25.
                        </li><li>The leaderboard on Kaggle that you can see is the Public Leaderboard, which is your accuracy for 50% of the testing data. Your final rankings will be based on the Private leaderboard, which is based on the other 50% of the testing data and will become public as soon as the competition ends. This is to prevent you from just writing a decision tree that overfits the testing data, which defeats the purpose.
                        </li></ol>
                        </p>
                    </section>
                </div>
            </div>

            <h4>Standard Rules and Procedures</h4>
                <p>These instructions are common to almost every competition, so we're only listing them once.</p>
                <p>
                <p><strong>To Participate:</strong></p>
                <ol>
                    <li>Create a <a href="https://kaggle.com">Kaggle</a> account if you don't already have one by clicking "sign up" in the top right.</li>
                    <li>Click on the competition link, which will be posted in the lecture table on <a href="../schedule/1718">this page</a>.</li>
                    <li>Download the training and testing data.</li>
                    <li>Download any shell code from the website.</li>
                    <li>Write your algorithm and train it on the training data.</li>
                    <li>Then, test it on the testing data, creating a submission file with the predicted ground truth in the format shown in the sample submission file.</li>
                    <li>Upload your submission file and see your results!</li>
                    <li>Tweak your code, repeating steps 5-8 to improve your accuracy and move up the leaderboard.
                </ol>
                <p><strong>Rules:</strong></p>
                <ol>
                    <li>Use Python. Everything we do is in Python this year. Unless otherwise specified, do not use any ML library other than numpy.</li>
                    <li>The Competition ends at 11:59:00 PM the following Tuesday.</li>
                    <li>The leaderboard on Kaggle that you can see is the public leaderboard, which is your accuracy for some percentage of the testing data.
                    Your final rankings will be based on the private leaderboard, which is based on the other part of the testing data and will become public as soon as the competition ends. This is to prevent you from just writing an algorithm to overfit the testing data, which defeats the purpose of the competition.</li>
                </ol>
            <!--End Competition Content-->


    <!--close main content-->
    </section>
    <!--close all non-footer content-->
    </div>
	<footer class="site-footer" style="background-image:linear-gradient(120deg, #272d39, #272d39);">
    <section class="main-content">
        <table style="border: 0px; width=100%;">
            <tr style="border: 0px">
                <td style="border:0px">
                    <a href="https://tjmachinelearning.com"><img src="../img/logo_alt.svg" width="150em" style="vertical-align:middle; margin-right:1em"></img></a>
                </td>
                <td style="border:0px; text-align: left">
                    <p style="color:#fff">TJ Machine Learning Club<br>6560 Braddock Rd, Alexandria, VA 22312<br><code style="background-color:#000"><a href="https://github.com/nikhilsardana/tjmachinelearning">Open-source</a></code>&nbsp;

                        <code style="background-color:#000"><a href="https://github.com/tjmachinelearning">Github</a></code></p>
                </td>
          </tr>
        </table>
    </section>
    </footer>
    <script src="../js/classie.js"></script>
	<script src="../js/demo1.js"></script>
  </body>
</html>
